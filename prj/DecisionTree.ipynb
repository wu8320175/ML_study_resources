{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[0, 0, 0, 0, 'no'],         #数据集\n",
    "                [0, 0, 0, 1, 'no'],\n",
    "                [0, 1, 0, 1, 'yes'],\n",
    "                [0, 1, 1, 0, 'yes'],\n",
    "                [0, 0, 0, 0, 'no'],\n",
    "                [1, 0, 0, 0, 'no'],\n",
    "                [1, 0, 0, 1, 'no'],\n",
    "                [1, 1, 1, 1, 'yes'],\n",
    "                [1, 0, 1, 2, 'yes'],\n",
    "                [1, 0, 1, 2, 'yes'],\n",
    "                [2, 0, 1, 2, 'yes'],\n",
    "                [2, 0, 1, 1, 'yes'],\n",
    "                [2, 1, 0, 1, 'yes'],\n",
    "                [2, 1, 0, 2, 'yes'],\n",
    "                [2, 0, 0, 0, 'no']]\n",
    "    labels = ['年龄', '有工作', '有自己的房子', '信贷情况']#分类属性\n",
    "    return dataSet, labels                #返回数据集和分类属性\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算香农熵\n",
    "#data:分类的列表\n",
    "def calcShannonEnt(data):\n",
    "    cot=Counter(list(data))\n",
    "    total=len(data)\n",
    "    H=0\n",
    "    for v in cot.values():\n",
    "        H+=v/total*math.log(v/total,2)\n",
    "    return -H\n",
    "\n",
    "\n",
    "DataSet,Labels=createDataSet()\n",
    "DataSet=np.array(DataSet)\n",
    "calcShannonEnt(DataSet[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判断是否非数值型\n",
    "def is_Continuous_values(dataSet):\n",
    "    flag=0\n",
    "    for i in dataSet:\n",
    "        try:\n",
    "            if isinstance(float(i),float):\n",
    "                flag=1\n",
    "            else:\n",
    "                return 0\n",
    "        except:\n",
    "            return 0\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#西瓜数据集测试\n",
    "with open('watermelon2.txt','r') as f:\n",
    "    lines=f.readlines()\n",
    "    dataSet=[]\n",
    "    for line in lines:\n",
    "        dataSet.append(line.replace('\\n','').split(','))\n",
    "        \n",
    "data=dataSet[1:]\n",
    "data=np.array(data)[:,1:]\n",
    "is_Continuous_values(data[:,-2])\n",
    "# Continuous_values_analysis(data[:,[-3,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#连续值处理\n",
    "def  Continuous_values_analysis(data):\n",
    "    X=data[:,0].astype(float)\n",
    "    X_temp=data[:,0].astype(float)\n",
    "    Y=data[:,-1]\n",
    "    length=len(X)\n",
    "    T=[]\n",
    "    X.sort()\n",
    "    for ix in range(1,length):\n",
    "        result=(X[ix]+X[ix-1])/2\n",
    "        T.append(result)\n",
    "    EntD=calcShannonEnt(Y)\n",
    "    maxgain=0\n",
    "    maxt=0\n",
    "    for t in T:\n",
    "        cate_list1=Y[np.where(X_temp>t)]\n",
    "        cate_list2=Y[np.where(X_temp<t)]\n",
    "        Ent1=calcShannonEnt(cate_list1)\n",
    "        Ent2=calcShannonEnt(cate_list2)\n",
    "        gain=EntD-len(cate_list1)/length*Ent1-len(cate_list2)/length*Ent2\n",
    "        if gain>maxgain:\n",
    "            list1,list2=np.where(X_temp>t),np.where(X_temp<t)\n",
    "            maxgain=gain\n",
    "            maxt=t\n",
    "    return maxgain,maxt,list1,list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset:numpy对象\n",
    "#return:返回特征增益的list\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    #计算信息增益，选择最优特征\n",
    "    #1.划分特征\n",
    "    #2.每列划分出不同类别\n",
    "    #3.每个类别对应的Y特征数量\n",
    "    row_len,column_len=dataSet.shape\n",
    "    label_col=dataSet[:,-1]\n",
    "    Hd=calcShannonEnt(label_col)\n",
    "    gs=[]#用于存储对应特征的增益\n",
    "    for col in range(0,column_len-1):\n",
    "        features=dataSet[:,col]\n",
    "        cot=Counter(features)\n",
    "        g=0\n",
    "        for cate,v in cot.items():\n",
    "            #该特征下为cate的所有行\n",
    "            cate_rows=np.where(features==cate)\n",
    "            #某类在对应Y的香农熵\n",
    "            Hi=calcShannonEnt(label_col[cate_rows])\n",
    "            g+=v/row_len*Hi\n",
    "        Gain=Hd-g#ID3算法\n",
    "        gs.append(Gain)\n",
    "    return gs\n",
    "    \n",
    "def chooseBestFeatureToSplit_index(dataSet):\n",
    "    #计算信息增益，选择最优特征\n",
    "    #1.划分特征\n",
    "    #2.每列划分出不同类别\n",
    "    #3.每个类别对应的Y特征数量\n",
    "    row_len,column_len=dataSet.shape\n",
    "    label_col=dataSet[:,-1]\n",
    "    Hd=calcShannonEnt(label_col)\n",
    "    gs=[]#用于存储对应特征的增益\n",
    "    for col in range(0,column_len-1):\n",
    "        features=dataSet[:,col]\n",
    "#         if is_Continuous_values(features):\n",
    "#             #是连续数值型\n",
    "#             pass\n",
    "        cot=Counter(features)\n",
    "        g=0\n",
    "        for cate,v in cot.items():\n",
    "            #该特征下为cate的所有行\n",
    "            cate_rows=np.where(features==cate)\n",
    "            #某类在对应Y的香农熵\n",
    "            Hi=calcShannonEnt(label_col[cate_rows])\n",
    "            g+=v/row_len*Hi\n",
    "        Gain=Hd-g\n",
    "        gs.append(Gain)\n",
    "    #ID3算法\n",
    "    max_Ent=max(gs)\n",
    "    index=gs.index(max_Ent)#返回最大信息增益的下标 \n",
    "    #C4.5算法\n",
    "    gs_array=np.array(gs)\n",
    "    gs_mean=np.mean(gs_array)\n",
    "    row_list=np.where(gs_array>gs_mean)\n",
    "    gs_RTmean_array=gs_array[row_list]\n",
    "    max_ix=index\n",
    "    max_Gain_radio=0\n",
    "    for num in list(gs_RTmean_array):\n",
    "        ix=gs.index(num)\n",
    "        IV=calcShannonEnt(dataSet[:,ix])\n",
    "        Gain_radio=num/IV\n",
    "        if Gain_radio>max_Gain_radio:\n",
    "            max_ix=ix\n",
    "            max_Gain_radio=Gain_radio\n",
    "    index=max_ix\n",
    "    return index\n",
    "\n",
    "#CART算法\n",
    "def Gini(dataSet):\n",
    "    cate_v=Counter(list(dataSet))\n",
    "    data_len=len(dataSet)\n",
    "    S=0\n",
    "    for k,v in cate_v.items():\n",
    "        S+=(v/data_len)**2\n",
    "    return 1-S\n",
    "\n",
    "def chooseBestFeatureToSplit_index_Gini(dataSet):\n",
    "    row_len,column_len=dataSet.shape\n",
    "    labels=dataSet[:,-1]\n",
    "    gini_list=[]\n",
    "    for col in range(column_len-1):\n",
    "        data_temp=dataSet[:,col]\n",
    "        S=0\n",
    "        for cate,v in Counter(data_temp).items():\n",
    "            row_list=np.where(data_temp==cate)\n",
    "            gi=Gini(labels[row_list])\n",
    "            S+=(v/row_len)*gi\n",
    "        gini_list.append(S)\n",
    "        \n",
    "    min_gini=min(gini_list)\n",
    "    min_gini_index=gini_list.index(min_gini)\n",
    "    return min_gini_index#返回最小gini值得下标\n",
    "# Gini(data[:,3])\n",
    "# chooseBestFeatureToSplit_index_Gini(data)\n",
    "#chooseBestFeatureToSplit(data)\n",
    "\n",
    "\n",
    "data,label=createDataSet()\n",
    "data=np.array(data)\n",
    "chooseBestFeatureToSplit_index(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功生成并存储决策树： {'有自己的房子': {'0': {'有工作': {'0': 'no', '1': 'yes'}}, '1': 'yes'}}\n"
     ]
    }
   ],
   "source": [
    "#{'有自己的房子': {0: {'有工作': {0: 'no', 1: 'yes'}}, 1: 'yes'}}['年龄', '有工作', '有自己的房子', '信贷情况']#分类属性\n",
    "#dataSet:numpy对象，数据集\n",
    "#labels：特征名['年龄', '有工作', '有自己的房子', '信贷情况']\n",
    "#catelist：特征分类[['a','b'],['1','2']]\n",
    "#\n",
    "def createTree(dataSet,labels,cates_list):\n",
    "    row_len,column_len=dataSet.shape\n",
    "    data_cates=dataSet[:,-1]\n",
    "    cates=Counter(data_cates).most_common()\n",
    "    if len(cates)==1:\n",
    "        #如果所有训练集都是一个分类,则设置为当前类别\n",
    "        return cates[0][0]\n",
    "    best_feature_index=chooseBestFeatureToSplit_index(dataSet)\n",
    "#    best_feature_index=chooseBestFeatureToSplit_index_Gini(dataSet)\n",
    "#     sort_gs=sorted(gs,reverse=True)\n",
    "#     best_feature_max_Ent=sort_gs[0]\n",
    "#     best_feature_index=gs.index(best_feature_max_Ent)\n",
    "    best_label=labels[best_feature_index]\n",
    "    best_feature_array=dataSet[:,best_feature_index]\n",
    "    #切割datsSet，labels\n",
    "    split_dataSets=np.delete(dataSet,best_feature_index,axis=1)\n",
    "    split_labels=labels.copy()\n",
    "    split_labels.pop(best_feature_index)\n",
    "    split_cates_list=cates_list.copy()\n",
    "    split_cates_list.pop(best_feature_index)\n",
    "    #\n",
    "    tree={best_label:{}}\n",
    "    for best_feature_cate in cates_list[best_feature_index]:\n",
    "        cate_row_indexs=np.where(best_feature_array==best_feature_cate)#对应类别的行标\n",
    "        split_dataSet=split_dataSets[list(cate_row_indexs[0]),:]\n",
    "        if split_dataSet.size==0:\n",
    "            #该分类的数据集为空，则设置为其父结点的最大分类\n",
    "            tree[best_label][best_feature_cate]=cates[0][0]\n",
    "        else:\n",
    "            tree[best_label][best_feature_cate]=createTree(split_dataSet,split_labels,split_cates_list) \n",
    "    return tree\n",
    "\n",
    "\n",
    "#得到每一个特征的分类:[['a','b'],['0','1'],['0','1','2']]\n",
    "def Elem2cates(dataSet):\n",
    "    row,col=dataSet.shape\n",
    "    cate_list=[]\n",
    "    for j in range(col):\n",
    "        cates=[]\n",
    "        for cate in set(dataSet[:,j]):\n",
    "            cates.append(cate)\n",
    "        cate_list.append(cates)\n",
    "    return cate_list\n",
    "\n",
    "#存入树\n",
    "def storeTree(tree,filename):\n",
    "    with open(filename,'w') as f:\n",
    "        f.write(json.dumps(tree))\n",
    "\n",
    "#读取树\n",
    "def loadTree(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        tree=f.read()\n",
    "    return json.loads(tree)\n",
    "\n",
    "#转换数据，并创建和存储树\n",
    "def Data2Tree(data,label,filename='tree.txt'):\n",
    "    data=np.array(data)\n",
    "    cates_list=Elem2cates(data)\n",
    "    tree=createTree(data,label,cates_list)\n",
    "    storeTree(tree,filename)\n",
    "    print('成功生成并存储决策树：',tree)\n",
    "# loadTree('tree.txt')    \n",
    "\n",
    "data,label=createDataSet()\n",
    "Data2Tree(data,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2624392604045631,\n",
       " 0.3815,\n",
       " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 12, 13, 15, 16], dtype=int64),),\n",
       " (array([ 9, 10, 11, 14], dtype=int64),))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#西瓜数据集测试\n",
    "with open('watermelon2.txt','r') as f:\n",
    "    lines=f.readlines()\n",
    "    dataSet=[]\n",
    "    for line in lines:\n",
    "        dataSet.append(line.replace('\\n','').split(','))\n",
    "        \n",
    "data=dataSet[1:]\n",
    "data=np.array(data)[:,1:]\n",
    "Continuous_values_analysis(data[:,[-3,-1]])\n",
    "# X=data[:,-3].astype(float)\n",
    "# X_temp=data[:,-3].astype(float)\n",
    "# Y=data[:,-1]\n",
    "# length=len(X)\n",
    "# T=[]\n",
    "# X.sort()\n",
    "# for ix in range(1,length):\n",
    "#     result=(X[ix]+X[ix-1])/2\n",
    "#     T.append(result)\n",
    "# EntD=calcShannonEnt(Y)\n",
    "# maxgain=0\n",
    "# maxt=0\n",
    "# for t in T:\n",
    "#     cate_list1=Y[np.where(X_temp>t)]\n",
    "#     cate_list2=Y[np.where(X_temp<t)]\n",
    "#     Ent1=calcShannonEnt(cate_list1)\n",
    "#     Ent2=calcShannonEnt(cate_list2)\n",
    "#     gain=EntD-len(cate_list1)/length*Ent1-len(cate_list2)/length*Ent2\n",
    "#     if gain>maxgain:\n",
    "#         maxgain=gain\n",
    "#         maxt=t\n",
    "\n",
    "# labels=dataSet[0][1:]\n",
    "# data=dataSet[1:]\n",
    "# data=np.array(data)[:,1:]\n",
    "# Data2Tree(data,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "放贷\n"
     ]
    }
   ],
   "source": [
    "def classify(tree,label,testvec):\n",
    "    #isinstance (a,int)\n",
    "    while isinstance(tree,dict):\n",
    "        #取标签名\n",
    "        items=list(tree.items())[0]\n",
    "        feature_index=label.index(items[0])\n",
    "        value=str(testvec[feature_index])\n",
    "        tree=items[1][value]\n",
    "    if tree=='yes':\n",
    "        print('放贷')\n",
    "    elif tree=='no':\n",
    "        print('不放贷')\n",
    "        \n",
    "featLabels=['有自己的房子','有工作']\n",
    "vec=[0,1]\n",
    "tree=loadTree('tree.txt')\n",
    "classify(tree,featLabels,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功生成并存储决策树： {'tearRate': {'normal': {'astigmatic': {'yes': {'prescript': {'hyper': {'age': {'young': 'hard', 'pre': 'no lenses', 'presbyopic': 'no lenses'}}, 'myope': 'hard'}}, 'no': {'age': {'young': 'soft', 'pre': 'soft', 'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}}}}}}, 'reduced': 'no lenses'}}\n"
     ]
    }
   ],
   "source": [
    "with open('lenses.txt','r') as f:\n",
    "    #print(f.readlines())\n",
    "    data=[]\n",
    "    for line in f.readlines():\n",
    "        data.append(line.replace('\\n','').split('\\t'))\n",
    "\n",
    "labels=['age','prescript','astigmatic','tearRate']\n",
    "Data2Tree(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "data,label=createDataSet()\n",
    "data=np.array(data)\n",
    "data1=data[:,0]\n",
    "b=np.where(data1=='p')\n",
    "c=data[b,:]\n",
    "c.size\n",
    "for i in set(data1):\n",
    "    print(i)\n",
    "\n",
    "# calcShannonEnt(data[:,-1][b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'yes', '0': {'有工作': {'1': 'yes', '0': 'no'}}}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={'有自己的房子': {'1': 'yes', '0': {'有工作': {'1': 'yes', '0': 'no'}}}}\n",
    "list(a.items())[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08300749985576883, 0.32365019815155627, 0.4199730940219749, 0.36298956253708536]\n",
      "[['0' '0' '0' '1' 'no']\n",
      " ['0' '1' '0' '1' 'yes']]\n"
     ]
    }
   ],
   "source": [
    "data,label=createDataSet()\n",
    "data=np.array(data)\n",
    "gs=chooseBestFeatureToSplit(data)\n",
    "print(gs)\n",
    "# gs=sorted(gs,reverse=True)\n",
    "np.delete(data,4,axis=1)\n",
    "print(data[[1,2],:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
