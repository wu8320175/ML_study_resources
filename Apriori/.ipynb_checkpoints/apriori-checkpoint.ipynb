{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    return [[1,3,4],[2,3,5],[1,2,3,5],[2,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
      "[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({5})] {frozenset({1}): 0.5, frozenset({3}): 0.75, frozenset({2}): 0.75, frozenset({5}): 0.75}\n"
     ]
    }
   ],
   "source": [
    "#[{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}]\n",
    "#根据原数据生成大小为1个的元素集C1\n",
    "def createC1(dataSet):\n",
    "    S=set()\n",
    "    for x in dataSet:\n",
    "        S=x|S\n",
    "    return [frozenset([x]) for x in S]\n",
    "#[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
    "\n",
    "\n",
    "#扫描C1集，去原数据集中扫描计算出支持度，排除掉C1中小于Support的项\n",
    "#S：C1集，D：原数据集，Support：支持度\n",
    "def scanD(S,D,Support):\n",
    "    scan_count=dict()\n",
    "    scan_score=dict()\n",
    "    for d in D:\n",
    "        for s in S:\n",
    "            if s.issubset(d):\n",
    "                if s in scan_count:\n",
    "                    scan_count[s]+=1\n",
    "                else:\n",
    "                    scan_count[s]=1\n",
    "    for k,v in scan_count.items():\n",
    "        value=v/len(D)\n",
    "        if value<Support:\n",
    "            S.remove(k)\n",
    "        else:\n",
    "            scan_score[k]=value\n",
    "    return S,scan_score\n",
    "\n",
    "#[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({5})]\n",
    "\n",
    "data=loadDataSet()\n",
    "data=list(map(set,data))\n",
    "C1=createC1(data)\n",
    "print(C1)\n",
    "C1,d=scanD(C1,data,0.5)\n",
    "print(C1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({5})], [frozenset({1, 3}), frozenset({2, 3}), frozenset({2, 5}), frozenset({3, 5})], [frozenset({2, 3, 5})]] {frozenset({1}): 0.5, frozenset({3}): 0.75, frozenset({2}): 0.75, frozenset({5}): 0.75, frozenset({1, 3}): 0.5, frozenset({2, 3}): 0.5, frozenset({2, 5}): 0.75, frozenset({3, 5}): 0.5, frozenset({2, 3, 5}): 0.5}\n"
     ]
    }
   ],
   "source": [
    "#根据C集生成非重复且元素长度为K的集合\n",
    "def apriori_Gen(Lk,k):\n",
    "    L_len=len(Lk)\n",
    "    L_temp=list()\n",
    "    for i in range(L_len):\n",
    "        for j in range(i+1,L_len):\n",
    "            if list(Lk[i])[:k-2]==list(Lk[j])[:k-2]:\n",
    "                L_temp.append(frozenset(Lk[i]|Lk[j]))\n",
    "    return L_temp\n",
    "#整个过程如下：\n",
    "#1.对原数据集生成非重复（k=1，长度为1）的元素初始集合C，\n",
    "#2.对C进行扫描去掉低于支持度的元素\n",
    "#3.对C集合并生成非重复的且（k=k+1）的元素集\n",
    "#4.重复2,3步骤，直到K长度等于原数据集中最长项的长度，C集合元素数量小于2个\n",
    "#频繁项 集每一条数据\n",
    "def apriori(data,support):\n",
    "    L_sum=[]\n",
    "    k=1\n",
    "    C1=createC1(data)\n",
    "    C1,SupportData=scanD(C1,data,support)\n",
    "    L_sum.append(C1)\n",
    "    k=k+1\n",
    "    Ci=apriori_Gen(C1,k)\n",
    "    while len(Ci)>=1:\n",
    "        Ci,support_temp=scanD(Ci,data,support)\n",
    "        L_sum.append(Ci)\n",
    "        SupportData.update(support_temp)\n",
    "        k=k+1\n",
    "        Ci=apriori_Gen(Ci,k)\n",
    "    return L_sum,SupportData\n",
    "\n",
    "data=loadDataSet()\n",
    "data=list(map(set,data))\n",
    "freqset_list,supportdata=apriori(data,0.5)\n",
    "print(freqset_list,supportdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({1}), frozenset({3}), 1.0),\n",
       " (frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({3, 5}), frozenset({2}), 1.0),\n",
       " (frozenset({2, 3}), frozenset({5}), 1.0)]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#L:频繁项集列表，频繁项的支持度，最小可信度\n",
    "def generateRules(L,supportdata,minconf=0.7):\n",
    "    L_len=len(L)\n",
    "    rule=[]\n",
    "    for i in range(1,L_len):\n",
    "        for items in L[i]:\n",
    "            item_set=[frozenset([x]) for x in items]\n",
    "            if i <=1:\n",
    "                #计算可信度并确定规则\n",
    "                item_list,rule_list=calConf(items,item_set,supportdata,minconf)\n",
    "                pass\n",
    "            else:\n",
    "                rule_list=rulesFromConseq(items,item_set,supportdata,minconf)\n",
    "                #\n",
    "                pass\n",
    "            rule+=rule_list\n",
    "    return rule\n",
    "#计算频繁项的可信度，并生成规则\n",
    "#某一个频繁项，频繁项单个元素的集合，所有项的支持度，最小可信度\n",
    "def calConf(items,item_set,supportdata,minconf):\n",
    "    rule_list=[]\n",
    "    item_list=[]\n",
    "    for item in item_set:\n",
    "        conf=supportdata[items]/supportdata[items-item]\n",
    "        if conf>=minconf:\n",
    "            #保留 items-》items-item的规则以及可信度\n",
    "            #将该item存入\n",
    "            rule_list.append((items-item,item,conf))\n",
    "            item_list.append(item)\n",
    "    return item_list,rule_list\n",
    "#返回根据该频繁项生成的后件表，以及规则表\n",
    "\n",
    "#频繁项集，对每一项，通过不断扩大后件所含元素的数量减少前件的元素数量，来形成每一个频繁项的\n",
    "#如：1,2,3 开始只从其中选1个作为后件，其他作为前件（如12-》3等），不断扩大后件元素数量 如1-》23\n",
    "def rulesFromConseq(freqset,item,supportdata,minconf):\n",
    "    freq_len=len(freqset)\n",
    "    item_len=len(item[0])\n",
    "    rule=[]\n",
    "    if item_len<freq_len:\n",
    "        #调整后件长度\n",
    "        #item_plus=apriori_Gen(item,item_len+1)\n",
    "        #item_plus,rule_list=calConf(freqset,item_plus,supportdata,micconf)\n",
    "        #item_plus=apriori_Gen(item,item_len+1)\n",
    "        item,rule_list=calConf(freqset,item,supportdata,minconf)\n",
    "        item_plus=apriori_Gen(item,item_len+1)\n",
    "        #item_plus=apriori_Gen(item,item_len+1)\n",
    "        rule+=rule_list\n",
    "        #如果后件表所含项大于1个，则可以继续合并\n",
    "        if len(item_plus)>1:\n",
    "            #print(rule)\n",
    "            #print(item_plus)\n",
    "            #print(freqset)\n",
    "            rule_list=rulesFromConseq(freqset,item_plus,supportdata,minconf)\n",
    "            rule+=rule_list\n",
    "    return rule\n",
    "\n",
    "\n",
    "\n",
    "# item_set=[frozenset([x]) for x in freqset_list[2][0]]\n",
    "# print(item_set)\n",
    "# print(freqset_list[2][0])\n",
    "# rulesFromConseq(freqset_list[2][0],item_set,supportdata,0.5)\n",
    "# item_list,rule_list=calConf(freqset_list[1][0],item_set,supportdata,0.7)\n",
    "# print(item_list,rule_list)\n",
    "generateRules(freqset_list,supportdata,0.7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "b=[{1,2,3},{3,4,5}]\n",
    "a=[1,2]\n",
    "b=[3,4]\n",
    "\n",
    "print(a+b)\n",
    "# frozenset([1,2])=={1,2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'76', '2'})\n",
      "frozenset({'39', '2'})\n",
      "frozenset({'28', '2'})\n",
      "frozenset({'59', '2'})\n",
      "frozenset({'2', '34'})\n",
      "frozenset({'85', '2'})\n",
      "frozenset({'23', '2'})\n",
      "frozenset({'63', '2'})\n",
      "frozenset({'2', '90'})\n",
      "frozenset({'86', '2'})\n",
      "frozenset({'2', '1'})\n",
      "frozenset({'36', '2'})\n",
      "frozenset({'53', '2'})\n",
      "frozenset({'2', '93'})\n",
      "frozenset({'67', '2'})\n"
     ]
    }
   ],
   "source": [
    "mushroom_data=[]\n",
    "with open('mushroom.dat') as f:\n",
    "    for line in f.readlines():\n",
    "        mushroom_data.append(line.split())\n",
    "mushroom_data=list(map(set,mushroom_data))\n",
    "L,support=apriori(mushroom_data,0.3)\n",
    "for item in L[1]:\n",
    "    if item.intersection('2'):\n",
    "        print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
